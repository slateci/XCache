{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts trace data from Elasticsearch and saves it in HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import scan\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select sites and time periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2018-08-01 00:00:00'\n",
    "end_date = '2018-09-01 00:00:00'\n",
    "site = 'AGLT2'\n",
    "\n",
    "print(\"start:\", start_date, \"end:\", end_date)\n",
    "start = int(pd.Timestamp(start_date).timestamp())\n",
    "end = int(pd.Timestamp(end_date).timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### select kind of traces to export and name your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'prod_AUG'\n",
    "my_query = {\n",
    "    \"_source\": [\"time_start\", \"time_end\", \"site\", \"event\", \"scope\", \"filename\", \"filesize\"],\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'must': [\n",
    "                {'range': {'time_start': {'gte': start, 'lt': end}}},\n",
    "                {'exists': {\"field\": \"filename\"}},\n",
    "                {'wildcard': {'site': site + '*'}},\n",
    "                # {'wildcard': {'filename': 'EVNT*'}},\n",
    "#                 {'wildcard': {'event': 'get_sm*'}},\n",
    "                {'term': {'event': 'get_sm'}}\n",
    "                # {'term': {'event': 'get_sm_a'}},\n",
    "                # {'term': {'event': 'download'}},\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "es = Elasticsearch(['atlas-kibana.mwt2.org:9200'], timeout=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll = scan(client=es, index=\"traces\", query=my_query)\n",
    "count = 0\n",
    "requests = []\n",
    "for res in scroll:\n",
    "    r = res['_source']\n",
    "    requests.append([r['scope'] + ':' + r['filename'], r['filesize'], r['time_start']])\n",
    "    \n",
    "    if not count % 100000:\n",
    "        print(count)\n",
    "    count = count + 1\n",
    "\n",
    "# all_accesses = pd.DataFrame(requests).sort_values(2)\n",
    "# all_accesses.columns = ['filename', 'filesize', 'transfer_start']\n",
    "# all_accesses.set_index('filename', drop=True, inplace=True)\n",
    "# all_accesses.to_hdf(site + '_' + dataset + '.h5', key=site, mode='w', complevel=1)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}